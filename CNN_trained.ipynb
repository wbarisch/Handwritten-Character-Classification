{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import os, os.path\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from PIL import Image\n",
    "# force gpu computing, when gpu library is available\n",
    "USE_GPU = True\n",
    "# for timing\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'train_loop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrain_loop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train, train_for_epochs, validate, plot_history\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'train_loop'"
     ]
    }
   ],
   "source": [
    "from train_loop import train, train_for_epochs, validate, plot_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Implementing a deep convolutional neural network (MNIST)\n",
    "---\n",
    "\n",
    "### The multilayer CNN architecture\n",
    "* also see [Stanford University's CS231n](https://cs231n.github.io/convolutional-networks/) (recommended read)\n",
    "* concerning *pooling* in particular, see also [Jason Brownlee's blog](https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/) (also recommended)\n",
    "\n",
    "<img src=\"./15_12.png\" width=700/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Loading and preprocessing the data\n",
    "* directly from available [*Torchvision Datasets*](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html)\n",
    "* might take a while when first loaded, but can be reused afterwards\n",
    "* parameter `root` is used to specify a local directory to put the data in\n",
    "* parameter `train` is used to specify whether data is to be used for training or testing the model\n",
    "* parameter `transform` is used to provide transformation logic. In this case we use the [ToTensor()](https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor) transformation. This converts the image to a Ptorch tensor and scales its values to the range [0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST loading started: 2024-10-16 20:47:20.395901\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:02<00:00, 3972752.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 277115.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 1936063.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 2004685.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "MNIST normalization finished 2024-10-16 20:47:35.005541 (duration: 0:00:14.609640)\n",
      "Len train dataset: 50000 -- Len test dataset: 10000 -- Len val dataset: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_mnist_normal = dt.datetime.now()\n",
    "print(f'MNIST loading started: {start_mnist_normal}')\n",
    "## MNIST dataset\n",
    "mnist_train = MNIST(root='data', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = MNIST(root='data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "#split of 10000 entries from the train data set as validation data set\n",
    "val_size = 10000\n",
    "train_size = len(mnist_train) - val_size\n",
    "mnist_train, mnist_valid = random_split(mnist_train, [train_size, val_size])\n",
    "\n",
    "finish_mnist_normal = dt.datetime.now()\n",
    "print(f'MNIST normalization finished {finish_mnist_normal} (duration: {finish_mnist_normal - start_mnist_normal})')\n",
    "print(f'Len train dataset: {len(mnist_train)} -- Len test dataset: {len(mnist_test)} -- Len val dataset: {len(mnist_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting some hyperparameters and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# use %%capture to suppress unwanted output\n",
    "BATCH_SIZE = 64\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert the dataset to a dataloader which handles batching of the data\n",
    "mnist_trainloader = DataLoader(mnist_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "mnist_valloader = DataLoader(mnist_valid, batch_size=BATCH_SIZE, shuffle=False)\n",
    "mnist_testloader = DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Implementing a CNN using PyTorch\n",
    "\n",
    "#### Hyperparameters for CNN layers in PyTorch\n",
    "\n",
    " * **[Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html):** `torch.nn.Conv2Dd`\n",
    "   * `in_channels`: Number of channels in the input image\n",
    "   * `out_channels `: Number of channels produced by the convolution\n",
    "   * `kernel_size`: form of receptive field\n",
    "   * `strides`: size of filter shifts\n",
    "   * `padding`: number of padded input fields $\\rightarrow$ *dimension* of layer-output\n",
    "   \n",
    "   \n",
    " * **[MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html):** `torch.nn.MaxPool2d`\n",
    "   * `kernel_size`: $\\rightarrow$ *dimensionality reduction* (in conjunction with `strides`)\n",
    "   * `strides`\n",
    "   * `padding`\n",
    "   \n",
    "   \n",
    " * **[Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)** `torch.nn.Dropout`\n",
    "   * `p`: probability to drop a neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Building a CNN with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the model by implementing it as a python class. Note we have to implement the nn.Module\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 1024)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Instantiating and showing the model structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (relu1): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (relu2): ReLU()\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=3136, out_features=1024, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the CNN model\n",
    "model = CNN()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: How many parameters (disregarding bias) does this CNN learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Model training\n",
    "As before, we will just use the go-to-criterion of `CrossEntropyLoss` in connection with the `Adam` optimizer. For an overview of existing optimization algorithms, have a look [here](https://www.analyticsvidhya.com/blog/2021/10/a-comprehensive-guide-on-deep-learning-optimizers/). However, we start by training for *just one epoch*, i.e., we present the entirety of the training data to the model for learning only once and we will check how well the model performs afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for training the network\n",
      "MNIST training started: 2024-10-16 20:47:56.014261\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_for_epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMNIST training started: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_train_mnist\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# run training, set binary to false since we have a multi label classification\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_for_epochs\u001b[49m(device, NUM_EPOCHS, model, mnist_trainloader, mnist_valloader, optimizer, criterion, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m finish_train_mnist \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMNIST training finished: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinish_train_mnist\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (duration: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinish_train_mnist\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_train_mnist\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_for_epochs' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Set the device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and USE_GPU else \"cpu\")\n",
    "print(f'Using {device} for training the network')\n",
    "\n",
    "# Move the model weights to the desired device\n",
    "model.to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "start_train_mnist = dt.datetime.now()\n",
    "\n",
    "print(f'MNIST training started: {start_train_mnist}')\n",
    "# run training, set binary to false since we have a multi label classification\n",
    "history = train_for_epochs(device, NUM_EPOCHS, model, mnist_trainloader, mnist_valloader, optimizer, criterion, binary=False)\n",
    "\n",
    "finish_train_mnist = dt.datetime.now()\n",
    "print(f'MNIST training finished: {finish_train_mnist} (duration: {finish_train_mnist - start_train_mnist})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Model quality\n",
    "Let's see how well the model did during training already and in particular, how well it generalizes to the unseen test data after just one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Acc. 94.90\n",
      "Val Acc. 98.29\n",
      "Test Acc. 99.35\n"
     ]
    }
   ],
   "source": [
    "train_acc = history['train']['accuracy'][0]\n",
    "val_acc = history['val']['accuracy'][0]\n",
    "_, test_acc = validate(device, model, mnist_testloader, criterion, binary=False)\n",
    "print(f'\\nTrain Acc. {train_acc:.2f}\\nVal Acc. {val_acc:.2f}\\nTest Acc. {test_acc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "So, due to the superior network architecture which is much better suited to the task at hand, it took just a few seconds of training to obtain a model performing much better than the general MLP we already looked at. What is also interesting: should you continue to train the model (see the next example below), you could stop after only 3 epochs, since at that point the validation accuracy will already be above 99% and will more or less stagnate from there on, while the training accuracy will continue to (marginally) increase. This just shows that the model starts memorizing the training data instead of becoming better on unseen data quite fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Classification of selected images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6])\n"
     ]
    }
   ],
   "source": [
    "# function for predicting the class for a given batch by a trained model\n",
    "def predict_batch(model, batch, binary=True):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        batch = batch.to(device)\n",
    "        #predict\n",
    "        outputs = model(batch)\n",
    "        # Get the prediction by selecting the class with the highest probability\n",
    "        if binary:\n",
    "#            predicted = torch.sigmoid(outputs)\n",
    "            predicted = torch.round(outputs)\n",
    "        else:\n",
    "#            predicted = torch.softmax(outputs, 1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "        return predicted.cpu(), outputs.cpu()\n",
    "\n",
    "batch_test = next(iter(mnist_testloader))\n",
    "\n",
    "preds, _ = predict_batch(model, batch_test[0][:12], binary=False)\n",
    "print((batch_test[0][1].shape))\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visual check\n",
    "with plt.ioff(): # only show the plot when prompted explicitly\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    for i in range(12):\n",
    "        correct = preds[i] == batch_test[1][i]\n",
    "        ax = fig.add_subplot(2, 6, i+1)\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        img = batch_test[0][i].view(28, 28)\n",
    "        ax.imshow(img, cmap='gray_r')\n",
    "        ax.text(0.9, 0.1, '{}'.format(preds[i]), \n",
    "                size=15, color='blue' if correct else 'red',\n",
    "                horizontalalignment='center',\n",
    "                verticalalignment='center', \n",
    "                transform=ax.transAxes)\n",
    "        ax.text(0.35, 0.1, '{}'.format('Correct' if correct else 'Incorrect'), \n",
    "            size=15, color='blue' if correct else 'red',\n",
    "            horizontalalignment='center',\n",
    "            verticalalignment='center', \n",
    "            transform=ax.transAxes)\n",
    "    \n",
    "#plt.savefig('figures/15_13.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,                   # Model to export\n",
    "    torch.rand(1,1,28,28).to(device),             # Input tensor for the model\n",
    "    \"cnnModelMnist.onnx\",          # Output file name\n",
    "    export_params=True,      # Store the trained parameter weights\n",
    "    opset_version=11,        # ONNX version (11 is a safe default)\n",
    "    do_constant_folding=True,# Constant folding for optimization\n",
    "    input_names=['input'],   # Input name (optional)\n",
    "    output_names=['output'], # Output name (optional)\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}} # Enable dynamic batch size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this, especially if you do not have a lot of VRAM\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input name: input\n",
      "Model output name: output\n",
      "tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.5882, 0.9922, 0.7922,\n",
      "           0.1216, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.1451, 0.9843, 0.9843, 0.9922,\n",
      "           0.4196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0824, 0.7725, 0.9843, 0.9843, 0.9922,\n",
      "           0.4196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.4314, 0.7451, 0.9843, 0.9843, 0.9843, 0.9922,\n",
      "           0.6627, 0.4275, 0.2431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.9922, 0.9843, 0.9843, 0.9843, 0.9843, 0.9922,\n",
      "           0.9843, 0.9843, 0.8627, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.7137, 1.0000, 0.9922, 0.9922, 0.9922, 0.9922, 0.9176,\n",
      "           0.8706, 0.9922, 0.9922, 0.9922, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.2471, 0.8667, 0.9922, 0.9843, 0.9843, 0.9843, 0.5765, 0.3020,\n",
      "           0.2431, 0.5020, 0.9843, 0.9843, 0.4118, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1255,\n",
      "           0.9059, 0.9843, 0.9922, 0.9843, 0.8627, 0.5373, 0.0392, 0.0000,\n",
      "           0.0000, 0.1216, 0.9020, 0.9843, 0.9529, 0.4431, 0.0196, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1451,\n",
      "           0.9843, 0.9843, 0.9922, 0.7373, 0.0784, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.4275, 0.9843, 0.9922, 0.9843, 0.1373, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1451,\n",
      "           0.9843, 0.9843, 0.7882, 0.1176, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.1216, 0.7843, 0.9922, 0.9843, 0.1373, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1451,\n",
      "           0.9922, 0.9922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.1255, 0.7922, 1.0000, 0.9922, 0.6431, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5490,\n",
      "           0.9843, 0.9843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.4275, 0.9843, 0.9922, 0.9843, 0.1373, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8510,\n",
      "           0.9843, 0.9843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0824, 0.2471, 0.9059, 0.9843, 0.9922, 0.9020, 0.1176, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8510,\n",
      "           0.9843, 0.9843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.5647, 0.9843, 0.9843, 0.9843, 0.8667, 0.2392, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8510,\n",
      "           0.9843, 0.9843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7137,\n",
      "           0.8667, 0.9843, 0.9843, 0.9843, 0.7059, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8549,\n",
      "           0.9922, 0.9922, 0.2863, 0.2863, 0.8941, 0.9922, 0.9922, 1.0000,\n",
      "           0.9922, 0.9922, 0.9922, 0.9922, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4431,\n",
      "           0.9843, 0.9843, 0.9922, 0.9843, 0.9843, 0.9843, 0.9843, 0.9922,\n",
      "           0.9843, 0.9843, 0.9843, 0.5765, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1216,\n",
      "           0.9020, 0.9843, 0.9922, 0.9843, 0.9843, 0.9843, 0.9843, 0.9922,\n",
      "           0.9020, 0.7412, 0.1373, 0.0392, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.2431, 0.5569, 0.9922, 0.9843, 0.9843, 0.9843, 0.9843, 0.9922,\n",
      "           0.4196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.2824, 0.6824, 0.9843, 0.6784, 0.2784, 0.2824,\n",
      "           0.1176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000]]]])\n",
      "Output tensor shape: (1, 10)\n",
      "Output tensor contents: \n",
      "[[ 16.31872   -10.841348  -10.621803  -12.137662  -10.807598   -8.725741\n",
      "   -2.3270946  -7.7613945  -6.15877    -3.1400597]]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model_path = \"cnnModelMnist.onnx\"  # Replace with your ONNX model path\n",
    "session = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "# Print model input/output details\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "print(f\"Model input name: {input_name}\")\n",
    "print(f\"Model output name: {output_name}\")\n",
    "\n",
    "# Create a dummy input to test the model\n",
    "# For example, if your model expects a tensor of shape (1, 1, 28, 28) like a CNN for MNIST\n",
    "# Get the input image tensor\n",
    "input_tensor = batch_test[0][3]  # Shape: [1, 28, 28]\n",
    "\n",
    "# Add a batch dimension to make it [1, 1, 28, 28]\n",
    "input_tensor = input_tensor.unsqueeze(0)  # Shape: [1, 1, 28, 28]\n",
    "#print(input_tensor)\n",
    "\n",
    "# Convert the PyTorch tensor to a NumPy array (since ONNX runtime uses NumPy)\n",
    "input_numpy = input_tensor.numpy().astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "# Run the model\n",
    "output = session.run([output_name], {input_name: input_numpy})\n",
    "\n",
    "# Get the output tensor\n",
    "output_tensor = output[0]\n",
    "\n",
    "# Display the output tensor size and contents\n",
    "print(f\"Output tensor shape: {output_tensor.shape}\")\n",
    "print(f\"Output tensor contents: \\n{output_tensor}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
